import requests
import re
import streamlit as st
import random

# ==========================================
# 1. ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Backend Core)
# ==========================================

def normalize_text(text):
    """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ ÙˆØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ù„Ù)"""
    text = re.sub(r'[\u064B-\u065F\u0670\u06D6-\u06ED\u06E5\u06E6]', '', text)
    text = re.sub(r'[Ø£Ø¥Ø¢]', 'Ø§', text)
    return text

@st.cache_resource
def load_quran_db():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØµØ­Ù Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙˆØªØ®Ø²ÙŠÙ†Ù‡ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©"""
    url = "https://raw.githubusercontent.com/risan/quran-json/main/dist/quran.json"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            data = response.json()
            quran_list = []
            for surah in data:
                s_name = surah['name']
                s_id = surah['id']
                for ayah in surah['verses']:
                    quran_list.append({
                        "ref": f"{s_name} ({s_id}:{ayah['id']})",
                        "uthmani": ayah['text'],
                        "normalized": normalize_text(ayah['text'])
                    })
            return quran_list
        return None
    except:
        return None

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù†Ø¯ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…Ù„Ù
QURAN_DATA = load_quran_db()

# ==========================================
# 2. Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø« (Search Tools)
# ==========================================

def search_multi_roots_tool(roots_list):
    """Ù„Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ù…Ø­Ù„Ù„: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ø°ÙˆØ± Ù„ØºÙˆÙŠØ©"""
    if not QURAN_DATA: return "âš ï¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø¬Ø§Ù‡Ø²Ø©."
    report = ""
    total_hits = 0
    for root in roots_list:
        root = normalize_text(root.strip())
        if len(root) < 3: continue
        chars = list(root)
        pattern = fr"\w*{chars[0]}\w*{chars[1]}\w*{chars[2]}\w*"
        matches = []
        for ayah in QURAN_DATA:
            if re.search(pattern, ayah["normalized"]):
                matches.append(f"- {ayah['uthmani']} [{ayah['ref']}]")
        count = len(matches)
        if count > 0:
            total_hits += 1
            sample = matches[:3]
            if count > 6: sample += random.sample(matches[3:], 3)
            elif count > 3: sample += matches[3:]
            report += f"\nğŸ’ **Ø§Ù„Ø¬Ø°Ø± ({root}):** ÙˆØ±Ø¯ {count} Ù…Ø±Ø©. Ø´ÙˆØ§Ù‡Ø¯:\n" + "\n".join(sample) + "\n___\n"
    if total_hits == 0: return "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªØ·Ø§Ø¨Ù‚."
    return report

def search_prophet_story_tool(prophet_name):
    """Ù„Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ù‚ØµØµÙŠ: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¢ÙŠØ§Øª Ù†Ø¨ÙŠ Ù…Ø¹ÙŠÙ†"""
    if not QURAN_DATA: return None
    name = normalize_text(prophet_name.strip())
    matches = []
    for ayah in QURAN_DATA:
        if name in ayah["normalized"]:
            matches.append(f"[{ayah['ref']}] {ayah['uthmani']}")
    
    if not matches: return None
    # Ù†Ø±Ø¬Ø¹ Ø£ÙƒØ¨Ø± Ù‚Ø¯Ø± Ù…Ù…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¢ÙŠØ§Øª Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚ (Ø£ÙˆÙ„ 60 Ø¢ÙŠØ© Ù…Ø«Ù„Ø§Ù‹)
    return "\n".join(matches[:60])